'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/reachy-docs/docs/getting-started/','title':"Getting Started",'content':"Getting Started You just received your Reachy and you want to start using it? You are in the right place!\nThe next sections will guide you in the steps required before turning your robot on. We make a great deal of efforts to make this process as simple and quick as possible. Yet, there are still a few steps to follow which are particularly important.\nSo, grab a cup of coffee (or anything else you like) and let's do it. It should take about TODO hours.\n First, you will see how to assemble the different parts of Reachy together. Then, you will connect to your robot. You will launch its first behavior!  "});index.add({'id':1,'href':'/reachy-docs/docs/getting-started/assemble-your-reachy/','title':"Assemble Your Reachy",'content':"Assemble your Reachy "});index.add({'id':2,'href':'/reachy-docs/docs/getting-started/connect-to-your-robot/','title':"Connect to Your Robot",'content':"Connect to your robot Everything is already installed ðŸŽ‰ Reachy comes with a Raspberry-Pi 4 dedicated to its control. When you receive your Reachy, the board is pre-installed with all required softwares. So, you don't have to install anything on your computer.\nThis section is meant to:\n let you know how to connect to the Raspberry-Pi, give you a bit more information on how things are actually working.  First, you can find the Raspberry-Pi inside the trunk of the robot, as shown on this picture:\nTODO\nThen, if you want to update or re-install the system, we recommend you to rewrite the whole image. You can use etcher to burn the ISO. You will need a SD-card with at least a 16Go capacity. You can find the latest ISO here.\nBackup\nMake sure to save and copy your work as it will be lost during the re-writing!\n The image is based on the Raspbian Buster OS (desktop version). We then installed our own software, mainly a few Python packages.\nInstall on your own machine\nWe provide a pre-install Raspberry-Pi to ensure that all Reachy are shipped ready to be used and with the same configuration. Yet, if you want to use your own computer to control Reachy, or if you want to customize the Raspbian image it is possible. It is a more complex approach and requires knowledge on development environment. Some components are dedicated to the Raspberry Pi (such as the camera and you will have to either use a Raspberry Pi or change the cameras).\n Connect to your Reachy What is left to configure is how you want to access your Reachy. There are a few options. We will present the most common below.\nWork directly on the robot You can directly plug a keyboard, mouse and display on the back of robot and you are good to go.\nLogin access\nThe robot comes with the default login: pi and a default password: reachy.\n TODO: image\nYou will have access to the Raspbian GUI where you will be able to configure everything you need (WiFi, ssh access, login, etc). Please, refer to the official Raspberry-Pi documentation for more information.\nAccess it via the network You can also work from your own computer and access the robot remotely. To do so, you will first need to connect the robot to your network.\nIf you already know how to connect a Raspberry-Pi, you can follow your usual procedure. The only modification from a \u0026ldquo;vanilla\u0026rdquo; Raspbian is the hostname:Â reachy and the default password:Â reachy.\nLogin access\nThe robot comes with the default login: pi and a default password: reachy. Make sure to change the password if you enable remote access! Or even better, only connect using ssh key.\n To connect to your robot, you will need to either:\n know its IP address on your network (see with your FAI or IT to get the information) use the mDNS protocol and access the robot via its hostname.  More information is accessible on the Raspberry-Pi official documentation.\nUsing the IP\nssh pi@192.168.0.42 Replace 192.168.0.42 with the IP you found.\n Using ZeroConf\nssh pi@reachy.local    Note: for information on how to use ssh on your own machine, please refer to the Raspberry-Pi documentation.\nUsing Ethernet You can connect your Reachy using the ethernet socket on the back of the robot. Most configuration should work without any additional setup.\nTODO: image\nConfiguring the WiFi Configuring the WiFi on a Raspberry-Pi for the first time can be a bit tricky. Here, again we strongly recommend to follow the official guide.\nThe simplest way, by far, is to first directly connect to the board via a keyboard and display (see this section) and use the GUI to configure the WiFi.\nYou can also first connect to the board via Ethernet and configure the WiFi via ssh in command line (see this documentation).\nFinally, if none of the options are available for you, you will need to open the robot and remove the SD-card to connect it to your computer and write the wpa_supplicant.conf file.\n"});index.add({'id':3,'href':'/reachy-docs/docs/getting-started/faq/','title':"FAQ",'content':"FAQ "});index.add({'id':4,'href':'/reachy-docs/docs/posts/safety/','title':"Safety First",'content':"Safety first  compliance torque temperature limit initial position speed  "});index.add({'id':5,'href':'/reachy-docs/docs/technical-specifications/','title':"Technical Specifications",'content':"Technical specifications "});index.add({'id':6,'href':'/reachy-docs/docs/technical-specifications/arm/','title':"Arm",'content':"Reachy's arm specifications Reachy's arm offers 7 degrees of movement.\nStandard version Animated by the following motors: 1 Dynamixel MX-106T, 3 Dynamixel MX-64AT, 1 Dynamixel MX-28AT and 2 Dynamixel AX-18A.\nPerformance version Animated by the following motors: 3 Dynamixel MX-106T, 1 Dynamixel MX-64AT, 2 Dynamixel MX-28AT and 1 Dynamixel AX-18A.\n"});index.add({'id':7,'href':'/reachy-docs/docs/technical-specifications/gripper/','title':"Gripper",'content':"Reachy's gripper specifications Animated by 1 Dynamixel AX-18A. Includes a micro load cell 0.78 Kg\n"});index.add({'id':8,'href':'/reachy-docs/docs/technical-specifications/head/','title':"Head",'content':"Reachy's head specifications Reachyâ€™s head features two cameras: one to observe its environment and another camera to focus on the task of manipulating. The head is animated by Orbita, a unique technology developed by Pollen Robotics\u0026rsquo; R\u0026amp;D team. This ball joint actuator allows unpreceded dynamic and multi-directional movement. With animated antennas, Reachy can convey many emotions to his audience.\nCoral development board G950-01456-01\nSee the head in action in this video: https://youtu.be/X9dgsLX_u9I\nCameras 2 Raspberry Pi cameras associated with 2 optical lenses (one macro and one wide angle). See details on Raspberry Pi Camera module here: https://www.raspberrypi.org/documentation/hardware/camera/\nOrbita neck joint Ball joint actuator that is composed of a parallel mechanism motorized by 3 DC Maxon motors. The control of each motor is done with a Pololu magnetic encoder and an LUOS DC motor module.\nAntennas Antennas are animated by a Dynamixel motor and are removable. A system of 3 magnets (2 south and 1 north) allow to attach the antennas to the rotation axis.\n"});index.add({'id':9,'href':'/reachy-docs/docs/program-your-robot/','title':"Program your robot",'content':"Program your robot This section will guide you in how to control your robot. It will describe the most basic features needed to make your robot move and interact with its environment.\nThe robot API is written in Python and version above 3.6 are supported. It is pre-installed on the Raspberry-Pi of the robot. So to program your Reachy you don't need to install anything on your own machine. Just connect to the Raspberry Pi as described in the Getting Started.\nWorking remotely on the robot is possible via ssh or using a Jupyter server (Jupyter is pre-installed on the Raspberry Pi).  The SDK has been designed to be accessible and easy-to-use. Yet, as it is fully open-source (available here), you can dig inside and adapt it to your specifics needs (contributions are welcome!).\nIn this section, we will cover:\n how to instantiate your robot and define the parts you are using, make the arm moves (motor by motor or using kinematics), recording and replay motions, make the head look somewhere specific, and run pre-defined behaviors.  The full Python's API is also accessible here.\nBefore actually running any code, we strongly recommend you to take a look at the Safety first section. It provides simple guidelines to avoid damaging your robot.  More advanced topics (like using advanced vision for the TicTacToe demo) will be discussed in their own chapter.\n"});index.add({'id':10,'href':'/reachy-docs/docs/program-your-robot/instantiate-your-robot/','title':"Instantiate Your Robot",'content':"Instantiate your robot The first step is to \u0026ldquo;instantiate\u0026rdquo; your robot. What we mean here, is that we will look for the different parts of your robot (connected via USBs on the Raspberry-Pi). We will identify them and check if all modules are connected.\nWe will also launch the synchronisation between the Raspberry-Pi and the different parts of your robot. The sensors value read from the robot will automatically be updated in your Python object. Similarly you will send command to your Robot effector hardware by simply affecting Python variables.\nWhich parts are present on my Reachy? Reachy is built around the concept of modular parts. A Reachy can be composed of:\n a trunk (with all electronics and power supply) one arm (left or right) or both with different kind of end-effectors a head    So, to instantiate your robot we have to specify which parts you want to use. If you are using a \u0026ldquo;full\u0026rdquo; Reachy, ie with both arm equipped with force gripper, and a head; you can run the following Python code on your Raspberry-Pi:\nfrom reachy import Reachy, parts reachy = Reachy( left_arm=LeftArm( luos_port=\u0026#39;/dev/ttyUSB*\u0026#39;, hand=\u0026#39;force_gripper\u0026#39;, ), right_arm=RightArm( luos_port=\u0026#39;/dev/ttyUSB*\u0026#39;, hand=\u0026#39;force_gripper\u0026#39;, ), head=Head( luos_port=\u0026#39;/dev/ttyUSB*\u0026#39;, camera_id=0, ), ) And if you have only the right arm and the head:\nfrom reachy import Reachy, parts reachy = Reachy( right_arm=RightArm( luos_port=\u0026#39;/dev/ttyUSB*\u0026#39;, hand=\u0026#39;force_gripper\u0026#39;, ), head=Head( camera_id=0, luos_port=\u0026#39;/dev/ttyUSB*\u0026#39;, ), ) If you don't see any error, good news, you are now connected to your Robot and all the parts have been found! ðŸŽ‰ ðŸŽ‰ ðŸŽ‰\nIf it didn't work, check the FAQ or the forum! Your problem is most likely already describe there.  Going deeper: the arm part Let's dive a bit into the details of the code above.\nfrom reachy import Reachy, parts Our API is available through the reachy Python module. This is the main entry point for controlling your robot.\nright_arm=RightArm( luos_port=\u0026#39;/dev/ttyUSB*\u0026#39;, hand=\u0026#39;force_gripper\u0026#39;, ), Here, we specify that we want to add a Right Arm part and it should be found on a USB serial port of type \u0026ldquo;/dev/ttyUSB*\u0026quot;. This is the standard name for the serial port on a Linux system. On other OS the name may differ (e.g. COM* on Windows).\nThen, we specify which types of hand are attached to the arm. In our cases we set it to \u0026ldquo;force_gripper\u0026rdquo;.\nGoing deeper: the head part head=Head( camera_id=0, luos_port=\u0026#39;/dev/ttyUSB*\u0026#39;, ), Similarly to the arm, we define the USB port on which we should find the part \u0026ldquo;/dev/ttyUSB*\u0026quot;. The camera_id corresponds to the index of the camera. It will be used to open the video stream using the OpenCV library.\nReachy: putting everything together The Reachy object is mainly a container to regroup the different parts. It also provides you higher level methods, for instance to program a complex motion happening on multiple parts at the same time.\nreachy = Reachy( left_arm=..., right_arm=..., head=..., ) Reachy's modularity: based on Luos technology To permit the parts system in Reachy, we are relying on the Luos technology. This modular system is based around the concept of using a tiny electronic Luos board for each sensors or effectors in your robot. They can be daisy chained and are automatically detected and recognized.\nThose modules are exposed to the Raspberry-Pi using a Luos gate that communicates via USB-serial interface.\nEach part is composed of several Luos modules:\n Arm  a dynamixel module to communicate with the motors a force sensor module for the gripper a gate to communicate with the Raspberry-Pi   Head  three DC motor controllers for Orbita a dynamixel module for the antennas a gate to communicate with the Raspberry-Pi    "});index.add({'id':11,'href':'/reachy-docs/docs/program-your-robot/control-the-arm/','title':"Control The Arm",'content':"Control the arm Once you have instantiated the Reachy object, you are actually connected to your robot. This means that the hardware (sensors and effectors) are synced with their software equivalent. This synchronization loop runs at about 100Hz. In particular, this lets you retrieve the arm(s) state and send commands to make them move.\nBefore actually running some commands, it's important to make sure you are ready:\n Make sure the robot is in a \u0026ldquo;safe\u0026rdquo; state (as shown in the images TODO for instance). If a wire is blocked or a motor is completly reversed, sending target position or even turning the motor on may result in a violent motion that may damage the robot. The motor are powerful so they can make the whole arm move fluidly. Do not hesitate to first try the move you want to make, with a low speed (we will show how to do that below). When you are sure everything is okay, you can increase the speed again.  More information is available on the Safety first section. It provides simple guidelines to avoid damaging your robot.  In the examples below, we will show examples on a right arm. Using the left arm instead should be straightforward. Always make sure that the different commands suggested below make sense in your context:\n angles from a right arm to a left arm may differ if your robot is attached in front of a desk or can freely move etc.   Everything is setup? It's time to make Reachy move!\nMoving individual motors Reachy's upper arm is composed of 4 motors:\n shoulder_pitch shoulder_roll arm_yaw elbow_pitch  And depending on the hand used, usually 3 or 4 others motors. For the force gripper, you have:\n forearm_yaw wrist_pitch wrist_roll gripper  Each of these motors can be controlled individually.\nHigher-level ways to control the whole arm are shown in the next sections.  They are servo motors that you control in position. You can also control their compliancy or their torque limit. Theses motors are also behaving as sensor, so their present position can also be read at any time.\nTo access a specific motor (here elbow_pitch) in Python code:\nreachy.right_arm.elbow_pitch \u0026gt;\u0026gt;\u0026gt; \u0026lt;DxlMotor \u0026#34;right_arm.elbow_pitch\u0026#34; pos=\u0026#34;-83.209\u0026#34; mode=\u0026#34;stiff\u0026#34;\u0026gt; And to get its present position:\nreachy.right_arm.elbow_pitch.present_position \u0026gt;\u0026gt;\u0026gt; -83.121 The codes above assume that you already instantiated your Reachy, as shown in the section Instantiate Your Robot and assigned it to the reachy variable.  In a more general manner, you can access any motor by using reachy.part_name.motor_name.\nPlease note that the part name can also be nested (e.g. right_arm.hand). All available parts are:\n right_arm right_arm.hand left_arm left_arm.hand head  If one part is not present in your robot, it's value will simply be None.\n For each motor, we have defined angle limits. They correspond to what moves the arm can actually make. For instance, the elbow pitch is limited from 0Â° to 125Â°. The forearm yaw can move from -150Â° to 150Â°.\nThe zero position of each motor is defined so as when all motors are at 0Â°, the arm is straight down along the trunk. For more information on the motor orientation and configuration, please refer to the section TODO.\nWhile each motors has angle limits corresponding to what it can do, all combinations of these limits are not reachable! When moving a motor, you always have to take into consideration the configuration of the other motors.  Compliant or stiff The servo motors used in Reachy's arm have two operating modes:\n compliant: the motors is soft and can be freely turned by hand. It cannot be controlled, setting a new target position will have no effect. Yet you can still read the motor position. stiff: the motors is hard and cannot be moved by hand. It can be controlled by setting new target position.  When you turn on your robot, all motors are compliant. You can freely move Reachy's arm and place it in its base position.\nTo make Reachy keep its position and let you control its motors, you need to turn them stiff. To do that, you can use the compliant property.\nFor instance, to make the elbow stiff, run the following code:\nreachy.right_arm.elbow_pitch.compliant = False Now, the elbow should be hard, you cannot move it by hand anymore.\nTo turn it back compliant, simply run:\nreachy.right_arm.elbow_pitch.compliant = True Setting a new target position for a motor Assuming the motor is now stiff, you can now make it move. Once again, make sure the target position you will set corresponds to a reachable position in your configuration.\nTo make our motor move, we will use the goto method. We will define a target position and a move duration. Let's try having our elbow at 90Â° in 2s:\nreachy.right_arm.elbow_pitch.goto( goal_position=90, # in degrees duration=2, # in seconds wait=True, ) When running this code, you should see the motor move.\nThe wait=True option blocks until the move is actually done. You can set it to False and the function will return immediatly.\nBe careful not to have two trajectories running on the same motor in parallel! This could result in an unpredicted behavior (Trajectory are not thread safe).\n Let's try to move another motor, the arm_yaw:\nreachy.right_arm.arm_yaw.goto( goal_position=20, duration=2, wait=True, ) Run this code\u0026hellip; And if you followed this documentation closely, your motor should not have moved\u0026hellip; Can you guess why? Yes, indeed the motor is still compliant. You have to turn it stiff and then run the code above again.\nAs a safety measure, when turning a motor stiff, its goal position is reset. This avoids to directly jump to a new position when you turn the motor stiff. Indeed, the target position is stored inside the motor and could be kept even if you restart your Python script.  goto vs goal_position To control \u0026amp; motor in the examples above we used the goto method. A lower API to control the motor is to directly use the goal_position property.\nYet, you should be careful when doing so, because the motor will try to reach this new goal position as fast as it can. And it is really fast (up until ~600-700 degrees per sec)! A workaround is to also use the moving_speed property to set the maximum speed that the motor can reach.\nreachy.right_arm.elbow_pitch.moving_speed = 50 # in degrees per sec  reachy.right_arm_elbow_pitch.goal_position = 110 # in degrees Yet, in our experience, when using this approach for controlling a motor, it may be hard to follow smoothly complex trajectories and have precise timing. You only set the maximum speed but have no control over the acceleration.\nThe approach used in the goto method differs in a sense that it only using position control (the maximum speed is allowed)\nA full position trajectory profile is actually generated going from the current position to the goal position. This trajectory is then interpolated at a predefined frequency (100Hz) to compute all intermediary target position that should be followed before reaching the final goal position. Depending on the interpolation mode chosen, you can have a better control over speed and acceleration. More details are given below.\nFor instance, the code below will make the elbow_pitch motor follow this curve (assuming the motor was still in 110Â°):\nreachy.right_arm.elbow_pitch.goto( goal_position=80, # in degrees duration=1, # in seconds wait=True, interpolation_mode='minjerk', ) Remember to reset the maximum speed of the elbow_pitch before runing any goto on it. To reset the maximum speed of a motor (using no speed limit) simply set it to 0:\nreachy.right_arm.elbow_pitch.moving_speed = 0   Moving multiple motors at once Most of the time when controlling a robot, you want to move multiple motors at once. While you can do it by running multiple goto and using the option wait=False, there is a simpler way.\nYou can actually use a goto the robot level and specify a list of (motor, target_position). This will create a trajectory for each motor and run them all in parallel.\nTo move both antennas at the same time, you can run:\nreachy.goto( goal_positions={ \u0026#39;head.left_antenna\u0026#39;: 90, \u0026#39;head.right_antenna\u0026#39;: -90, }, duration=2, wait=True, ) Note the use of the complete motor name (eg. \u0026lsquo;head.left_antenna\u0026rsquo;) as a key string in the goal_positions dict.  Motors from different parts can be mixed in the same goto.\nreachy.goto( goal_positions={ \u0026#39;head.left_antenna\u0026#39;: 0, \u0026#39;head.right_antenna\u0026#39;: 0, \u0026#39;right_arm.elbow_pitch\u0026#39;: 90, }, duration=2, wait=True, ) You can concatenate multiple goto simply by using the wait=True option and running both codes sequentially:\nreachy.goto( goal_positions={ \u0026#39;head.left_antenna\u0026#39;: 90, \u0026#39;head.right_antenna\u0026#39;: -90, }, duration=2, wait=True, ) reachy.goto( goal_positions={ \u0026#39;head.left_antenna\u0026#39;: 0, \u0026#39;head.right_antenna\u0026#39;: 0, }, duration=1, wait=True, ) You can also define positions, save them and then directly go to those positions.\nupper_pos = { \u0026#39;head.left_antenna\u0026#39;: 0, \u0026#39;head.right_antenna\u0026#39;: 0, } lower_pos = { \u0026#39;head.left_antenna\u0026#39;: 90, \u0026#39;head.right_antenna\u0026#39;: -90, } for _ in range(3): reachy.goto(goal_positions=lower_pos, duration=2, wait=True) reachy.goto(goal_positions=upper_pos, duration=1, wait=True) An easy way to define a position is to actually record it directly on the robot. To do that, you can play with the compliant mode so you can freely move the robot and make it adopt the position you want. Then, you can record its position using a code similar to:\narm_position = { motor.name: motor.present_position for motor in reachy.right_arm.motors } reachy_whole_position = { motor.name: motor.present_position for motor in reachy.motors } Make sure only the motors you want to track are actually included in the position you have recorded.\n Different trajectory interpolation All goto accept a interpolation_mode argument. This lets you define the way you want the trajectory to interpolate from A to B.\nIt cames with two basic way:\n linear interpolation minimum jerk  Running the same goto (from 0Â° to 90Â°) and changing the interpolation mode from linear to minjerk will result in the two different trajectories:\nNote that both trajectories start and finish at the same points. Yet, the followed positions and therefore speed and acceleration differs quite a bit. The Minimum Jerk will slowly accelerate at the begining and slowly decelerate at the end.\nWhat's show in the figure above is a theoretical trajectory. The motor has a low level controller that will try to follow this curve as closely as possible. Yet, depending on the speed/acceleration that you try to reach and the motor configuration, if it has to move a big loads, the real and theoretical curves may differ.  Grasping While the motors of the Force Gripper hand can be controlled like the rest of the motors of the arm, there is an additional functionality that lets you easily close and open the gripper.\nOpening the gripper is as simple as:\nreachy.right_arm.hand.open() This actually simply runs a goto on the gripper motor with pre-defined target position (-30Â°) and duration (1s).\nMore interestingly, you can also use the close method:\nreachy.right_arm.hand.close() This also runs a goto on the gripper, but it uses the force sensor inside the gripper to detect when it did grab something. It will try to automatically adjust the grip, to maintain enough force to hold the object while not forcing too much and overheat the motor.\nAll parameters used in the close method can be adjusted depending on your needs (please refer to the the APIs for more details.)\nThe gripper on Reachy's end effector is not meant to hold objects for a long time. The motor used in the gripper will quickly overload if doing so. Holding objects as you can see on the TicTacToe demo for instance is a good approximation of what the robot can do for long period of time (hold ~5s rest ~10s).\nIf you need to hold objects for longer period of time, you probably need to have a specific gripper for this task. While this is part of Pollen Robotics plan, we do not yet have a ready-to-use solution for this kind of use. Let us know if you would be interested in such features or want to help design one.\n The Force Gripper also gives you access to the current grip_force. The load sensor is located inside Reachy's gripper. It measures the force applied on the gripper (exactly it measures the deformation of the gripper due to the grasping).\nprint(reachy.right_arm.hand.grip_force) \u0026gt;\u0026gt;\u0026gt;TODO The returned value is nor accurate nor express in a standard unit system. Only relative values should be taken into account.\nFor instance:\nif abs(reachy.right_arm.hand.grip_force) \u0026lt; 50: print(\u0026#39;not holding\u0026#39;) else: print(\u0026#39;holding\u0026#39;)   Record \u0026amp; Replay Trajectories So far, we have showed you how to make your robot move using goto and pre-defined position. This works well for simple motion. But sometimes you would like to have more complex motions. That's when another technique comes into place: recording by demonstration.\nRecord by demonstration With this approach, you will demonstrate whole trajectories on Reachy by moving it by hand (using the compliant mode) and record its position at high-frequency (about 100Hz). Depending on what you want, you can record a single motor, or multiple at the same time. We provide a TrajectoryRecorder object that makes this process really simple.\nFor instance, assuming you want to record a movement on the Right Arm and that it is already compliant:\nrecorder = TrajectoryRecorder(reachy.right_arm.motors) And when you are ready to record:\nrecorder.start() And when the movement is over:\nrecorder.stop() The recorded trajectories can then be accessed via:\nprint(recorder.trajectories) \u0026gt;\u0026gt;\u0026gt; TODO You can save it as a numpy array using:\nimport numpy as np np.savez(\u0026#39;my-recorded-trajectory.npz\u0026#39;, **recorder.trajectories) The recorder can be restart as many times as you want. A new trajectory will be recorded on store as recorder.trajectories.\nYou can record any list of motors. For instance if you want to record the left antenna and the gripper you can use:\nrecorded_motors = [reachy.head.left_antenna, reachy.right_arm.hand.gripper] recorder = TrajectoryRecorder(recorded_motors) recorder.start() time.sleep(10) recorder.stop() Replay a trajectory Let's say you have recorded a nice motion and save it on the disk using the code above. You can first reload it at any time using:\nmy_loaded_trajectory = np.load(\u0026#39;my-recorded-trajectory.npz\u0026#39;) Then, you want to play it on the robot. To do that, we have created an object called TrajectoryPlayer. It can be used as follow:\ntrajectory_player = TrajectoryPlayer(reachy, my_loaded_trajectory) First, you need to specify on which robot you want to play the trajectory. If you have multiple Reachy, you can record a movement on one and play it on the other. Then, you need to specify which trajectory you want to play.\nAssuming the motors you want to use to play the trajectory are stiff and that the robot is in position where he can play the trajectory:\ntrajectory_player.play(wait=True, fade_in_duration=1.0) The code above will play the trajectory, wait for it to finish.\nThe fade_in_duration ensure there is no jump at the begining of the motion. Indeed, if you play a trajectory from a different starting point that what you record, the robot will try to reach this starting position as fast as it can. This parameter basically says, \u0026ldquo;first goto the recorded starting position in 1s, then play the trajectory\u0026rdquo;.\nAlways think about starting position before recording and replaying trajectories!\n You can also play multiple trajectories as a sequence. Assuming you have recorded three motion (traj_1, traj_2 and traj_3):\nTrajectoryPlayer(reachy, traj_1).play(wait=True, fade_in_duration=1) TrajectoryPlayer(reachy, traj_2).play(wait=True, fade_in_duration=1) TrajectoryPlayer(reachy, traj_3).play(wait=True, fade_in_duration=1) or in a more concise way:\nfor traj in [traj_1, traj_2, traj_3]: TrajectoryPlayer(reachy, traj).play(wait=True, fade_in_duration=1) Work on a trajectory - Smoothing Recorded trajectories are actually simple objects. It's a dict in the form:\n{motor_name: numpy_array_of_position}\nPosition arrays have the same length for all motors. You can thus convert the whole trajectory as a 2D array of shape MxS where M is the number of motor and S is the number of sample in the trajectory. The number of sample corresponds roughly to the duration in seconds x 100 (the default sampling frequency).\nBy recording a trajectory by demonstration, you may sometimes also record involuntary movements or jerkiness. When replayed, you may observe such artefacts. A good practice is to actually apply some smoothing/filtering on the trajectory before saving it.\nAs they are store as numpy arrays, you can use all typical libraries for this task (numpy/scipy/etc). Depending on the type of movements you recorded or what you want to do (eg. really smooth and slow moves, accurate trajectory, etc), the smoothing you want to apply may vary and there is not a single approach that will work for all types of moves.\nWe still provide a cubic smooth functionalities as it is something we often use. The cubic smoothing will garantee to have continuous acceleration which is really important for human perception. You simply need to choose the number of keypoints that will be used to represent your smoothed trajectory.\nfrom reachy.trajectory.interpolation import cubic_smooth smoothed_trajectories = cubic_smooth(recorder.trajectories, nb_kp=10) The cubic smooth function will keep the same number of samples by default. But you can modify this behavior using the out_points parameters.  Forward \u0026amp; Inverse Kinematics In all examples above, we have used joint coordinates. This means that we have controlled each joint separately. This can be hard and is often far from what we actually do as humans. When we want to grasp an object in front of us, we think of where we should put our hand, not how to flex each individual muscle to reach this position. This approach relies on the cartesian coordinates: the 3D position and orientation in space.\nForward and Inverse Kinematics is a way to go from one coordinates system to the other:\n forward kinematics: joint coordinates \u0026ndash;\u0026gt; cartesian coordinates inverse kinematics: cartesian coordinates \u0026ndash;\u0026gt; joint coordinates  Kinematic model We have defined the whole kinematic model of the arm. On a right arm equipped with a force gripper this actually look like this:\n shoulder_pitch - translation: [0, -0.19, 0] rotation: [0, 1, 0] shoulder_roll - translation: [0, 0, 0] rotation: [1, 0, 0] arm_yaw - translation: [0, 0, 0] rotation: [0, 0, 1] elbow_pitch - translation: [0, 0, -0.307] rotation: [0, 1, 0] forearm_yaw - translation: [0, 0, 0] rotation: [0, 0, 1] wrist_pitch - translation: [0, 0, -0.224] rotation: [0, 1, 0] wrist_roll - translation: [0, 0, -0.032] rotation: [1, 0, 0] gripper - translation: [0, -0.185, -0.06] rotation: [0, 0, 0]  This describe the translation and rotation needed to go from the previous motor to the next one. We actually use a simplified Denavit hHrtenberg notation.\nForward kinematics Using these parameters we can actually compute the 3D position and orientation of any joint in the arm considering their joint angles. This can indeed be formalized as a trigonometry problem.\nWe provide a function to directly compute the forward kinematics of a reachy arm. Assuming you are working on a Right Arm with a Force Gripper (8 joints), you can find the pose when all motors are at their zero position:\nprint(reachy.right_arm.forward_kinematics(joints_position=[0, 0, 0, 0, 0, 0, 0, 0])) \u0026gt;\u0026gt;\u0026gt; TODO The 4x4 matrix returned by the forward kinematics method is what is often called a pose. It actually encodes both the 3D translation and the 3D rotation into one single representation. $$ \\begin{bmatrix} R_{11} \u0026amp; R_{12} \u0026amp; R_{13} \u0026amp; T_x\\\\\\\nR_{21} \u0026amp; R_{22} \u0026amp; R_{23} \u0026amp; T_y\\\\\\\nR_{31} \u0026amp; R_{32} \u0026amp; R_{33} \u0026amp; T_z\\\\\\\n0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} $$  You can also get the current pose by doing:\ncurrent_position = [m.present_position for m in reachy.right_arm.motors] print(reachy.right_arm.forward_kinematics(joints_position=current_position)) \u0026gt;\u0026gt;\u0026gt; TODO If you are using an external 3D tracker, you may observe difference between the measure end effector position and the one given by the forward kinematics.\nKeep in mind that the forward kinematics rely on a theoretical model of the Reachy arm. You may have difference due to motor jerk or assembly approximation.\n Inverse kinematics Knowing where you arm is located in the 3D space can be useful but most of the time what you want is to move the arm in cartesian coordinates. You want to have the possibility to say: \u0026ldquo;move your hand to [x, y, z] with a 90Â° rotation around Z axis\u0026rdquo;.\nThis is what inverse kinematics does. We have provided a method to help you. You need to give it a 4x4 target pose (as defined in the forward kinematics) and an initial joint state.\nTODO: cool example Yet, it's important to understand that while the forward kinematics has a unique and well defined solution, the inverse kinematics is a much harder and ill defined problem.\nFirst, a Right Arm with a Gripper has 8 Degrees Of Freedom (8 motors) meaning that you may have multiple solutions to reach the same 3D point in space.\nSecond, at the moment, the inverse kinematics is computed using an approximation method that may take time to converge. You also need to give it a starting point that may have a tremendous influence on the final result.\nMultiple approaches exist for tackling the inverse kinematics problem. We have provided the most straightforward one, using black box optimization, that work in a general context. Yet, we intend to provide other ones more dedicated to specific context:\n having more natural movement minimizing change when performing whole cartesian trajectory computation speed \u0026hellip;   "});index.add({'id':12,'href':'/reachy-docs/docs/program-your-robot/control-the-head/','title':"Control The Head",'content':"Control the head Looking around Run predefined behaviors Look at specific points in space Move antennas Access the camera "});index.add({'id':13,'href':'/reachy-docs/docs/program-your-robot/pick-and-place/','title':"Pick and Place",'content':"Pick and Place Prepare Reachy workspace With all motors compliant try if you can realise the task you would like the robot to do. We will realise most of the recordings using physical demonstration.\nChoose a good starting point Define a resting position Rest between motions. Real rest position (even turn the motor compliant if possible).\nThe rest position should not force! Static forcing is how the motors heat the fastest.  Record a trajectory from reachy.trajectory import TrajectoryRecorder traj_recorder = TrajectoryRecorder(reachy.right_arm.motors) Compensating gravity  Record the pick trajectory traj_recorder.start() traj_recorder.stop() import numpy as np pick_traj = traj_recorder.trajectories np.savez(\u0026#39;pick-traj.npz\u0026#39;, **pick_traj) Record the place trajectory traj_recorder.start() traj_recorder.stop() import numpy as np place_traj = traj_recorder.trajectories np.savez(\u0026#39;place-traj.npz\u0026#39;, **place_traj) Record the back trajectory traj_recorder.start() traj_recorder.stop() import numpy as np back_traj = traj_recorder.trajectories np.savez(\u0026#39;back-traj.npz\u0026#39;, **back_traj) Putting everything together from reachy.trajectory import TrajectoryPlayer goto_base_position(duration=2) TrajectoryPlayer(reachy, pick_traj).play(wait=True) reachy.right_arm.hand.close() TrajectoryPlayer(reachy, place_traj).play(wait=True) reachy.right_arm.hand.open() TrajectoryPlayer(reachy, back_traj).play(wait=True) goto_resting_position(duration=2) Open \u0026amp; close the gripper Look what you are doing Make it loop "});index.add({'id':14,'href':'/reachy-docs/docs/program-your-robot/ai/','title':"AI \u0026 Coral TPU",'content':"AI \u0026amp; Google Coral TPU "});index.add({'id':15,'href':'/reachy-docs/docs/program-your-robot/python-api/','title':"Python's API",'content':"Python's API The whole Python's API is available here: https://pollen-robotics.github.io/reachy/.\nThe inline documentation can also be accessed directly from Python using instrospection. For instance:\nIn [1]: from reachy import Reachy In [2]: print(Reachy.__doc__) Class representing the connection with the hardware robot. Connect and synchronize with the hardware robot. Args: left_arm (reachy.parts.LeftArm): left arm part if present or None if absent right_arm (reachy.parts.RightArm): right arm part if present or None if absent head (reachy.parts.Head): hrad part if present or None if absent It can be used to monitor real time robot state and to send commands. Mainly a container to hold the different parts of Reachy together. In [3]: help(Reachy) "});index.add({'id':16,'href':'/reachy-docs/docs/tictactoe/','title':"TicTacToe Playground",'content':"TicTacToe Playground The TicTacToe Playground is the first setup we designed with Reachy. We wanted to create a demo to emphasize Reachy's interactivity both with humans and when grasping and moving objects. We also wanted to wrap it as a game as it constrains the interaction (turn-taking, game rules are already known) and well it's fun ðŸ˜„\nThis setup requires a Reachy:\n with a Right Arm to move the pawn and a Head to look and analyze the board.  The robot is attached to a table where the board and the pawn are setup. The dimensions of the table, the board, and the fixation where chosen to permit Reachy to reach and grab easily objects on the table surface.\nThe rest of this section will show you how to run and play the TicTacToe demonstration. It will also give you details on how to customize or adapt some of its key aspects to really fit your needs.\nThe TicTacToe demo The demo lets you play TicTacToe against your Reachy. Reachy plays with the cylinder pawn and you play with the square ones.\nThe demo has been made to be fully autonomous. So, Reachy decides who goes first (it's actually random) and let you know: it will either point to itself or point to you.\nReachy will detects when you place a pawn on the board and automatically plays in response. The game will last until one the player wins or if all pawns have been played. The robot will then react to the end of the game, differently whether it wins or loses. Then, it waits for the board to be cleaned and automatically restarts a new game.\nKey technical aspects This demonstration emphasises several key aspects of the robot:\n It involves complex motions that have been defined, saved and can be re-played (grasping a pawn, place it on a pre-defined location). It uses the camera, vision and machine learning for recognizing the board and analyzing its configuration. It also relies on a simple machine learning algorithm for correctly playing the game itself (what next move should I make).  "});index.add({'id':17,'href':'/reachy-docs/docs/tictactoe/setup-the-demo/','title':"Setup The Demo",'content':"Setup the demo On the ISO provided with the robot, the code to run the TicTacToe playground is already pre-installed. From your Raspberry-Pi board, you can find in the folder ~/dev/reachy-tictactoe.\nInside, you will find:\n the code implementing the gameplay mechanisms, the specific assets: move trajectories, pre-trained vision network a service file to simplify launching  Launch the demo at boot The easiest way to setup the demo is to launch it automatically at startup. Once setup, all you have to do is turn on the robot and after about 30s (basically the Raspberry-Pi boot time), it will directly start playing.\nMake sure you put the robot in a \u0026ldquo;safe\u0026rdquo; position before turning it on. Indeed, as soon as it starts it will try to move to its rest position.\nTODO: image\n We provide a pre-configured service file. So, to make it run automatically at startup, you need to:\n connect to your Raspberry-Pi run the following command:  sudo systemctl enable tictactoe_launcher.service   restart your Raspberry-Pi wait for about 30s and you should see the behavior starting  You only need to do this operation one time. Then, the demo will always start when the robot is turned on.\n If you want to stop the demo, run:  sudo systemctl stop tictactoe_launcher.service   If you want to disable the auto-launch behavior, run:  sudo systemctl disable tictactoe_launcher.service     "});index.add({'id':18,'href':'/reachy-docs/docs/tictactoe/playing-with-reachy/','title':"Playing With Reachy",'content':"Playing with Reachy Unwrapping the demo Controlling the demo As you can see on the diagram, the demo runs in a fully autonomous way. Yet, they are a few way you can control and interact with it.\n  First, the robot will start a game only once the board is cleared. It is up to you to reset the board position and to put back the pawn to their base positions. The robot will only start playing when it's done. When a game is over, a new one is directly restarted. So, at the end of a game clean up the board, and a new game will begin.\n  Then, if something weird happen during a game (like someone cheating, the detection was wrong and so we don't know our current state anymore, etc.), the robot will reset the game. It will perform a shuffle move, where Reachy will overthrow all pawns present on the board. It will then wait for a new game to begin, ie when the board is cleaned again. You can use this behavior to reset the game whenever you want. Simply starts cleaning the board, the robot will be lost, do its shuffle move and start a new game.\n  "});index.add({'id':19,'href':'/reachy-docs/docs/tictactoe/train-your-own-detection/','title':"Train Your Own Vision Detection",'content':"Train your own vision detection Take pictures of the board board, img = tp.reachy.analyze_board() Organize and get your data ready Train your classifier Use your own trained versions "});index.add({'id':20,'href':'/reachy-docs/categories/','title':"Categories",'content':""});index.add({'id':21,'href':'/reachy-docs/docs/','title':"Docs",'content':""});index.add({'id':22,'href':'/reachy-docs/','title':"Introduction",'content':"Hello, I'm Reachy! Reachy is an open source interactive robot designed to explore real-world applications!\n  Reachy makes AI \u0026amp; robotics accessible to researchers, innovation professionals and creatives. It comes in different flavors to let you prototype and create your real-world interactive \u0026amp; service applications right away!\u2029This manual will guide you in all the steps to\n finish the hardware assembly of your robot, turn it on for the first time, start using of our playground environment, or program it yourself.  You will also find many use examples, specifications and detail implementations. If you are missing some information or want to go deeper and interact with other Reachy's user, don't hesitate to join the discussion on our forum!\n"});index.add({'id':23,'href':'/reachy-docs/tags/','title':"Tags",'content':""});})();